[1] Kola, I.; Landis, J. Can the pharmaceutical industry reduce attrition rates? Nat. Rev. Drug Discov. 2004, 3, 711–716.

[2] Torjesen, I. Drug Development: The Journey of a Medicine from Lab to Shelf. Available online:https://www.pharmaceutical-journal.com/publications/tomorrows-pharmacist/drug-development-the-journey-of-a-medicine-from-lab-to-shelf/20068196.article?firstPass=false (accessed on 10 December 2020).

[3] Chan, H. S.; Shan, H.; Dahoun, T.; Vogel, H.; Yuan, S., Advancing drug discovery via artificial intelligence.Trends in pharmacological sciences 2019.

[4] Dickson, M.; Gagnon, J. P., The cost of new drug discovery and development. Discovery medicine 2009,4, 172-179.

[5] D. G. Brown, H. J. Wobst. A decade of fda­approved drugs (2010–2019): Trends and futuredirections[J]. Journal of Medicinal Chemistry, 2021



[6] Mullard A. The drug-maker’s guide to the galaxy. Nature News 2017; 549(7673): 445.

[7] Polishchuk PG, Madzhidov TI, Varnek A. Estimation of the size of drug-like chemical space based on GDB-17 data. J Comput Aided Mol Des 2013; 27(8): 675–9.



[8] Hert J, Irwin JJ, Laggner C, et al. Quantifying biogenic bias in screening libraries. Nat Chem Biol 2009; 5(7): 479–83.

[9] Schneider, P.; Schneider, G. De Novo Design at the Edge of Chaos. J. Med. Chem. 2016, 59, 4077–4086.

[10] Devi, R.V.; Sathya, S.S.; Coumar, M.S. Evolutionary algorithms for de novo drug design—A survey. Appl. Soft Comput. 2015, 27,543–552.



[11] Brown, N., Fiscato, M., Segler, M.H., & Vaucher, A.C. (2019). GuacaMol: Benchmarking Models for De Novo Molecular Design. *Journal of chemical information and modeling, 59 3*, 1096-1108 .

[12] Polykovskiy, D., Zhebrak, A., Sánchez-Lengeling, B., Golovanov, S., Tatanov, O., Belyaev, S., Kurbanov, R., Artamonov, A., Aladinskiy, V., Veselov, M., Kadurin, A., Nikolenko, S.I., Aspuru-Guzik, A., & Zhavoronkov, A. (2020). Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models. *Frontiers in Pharmacology, 11*.

[13]Hilten, N.V., Chevillard, F., & Kolb, P. (2019). Virtual Compound Libraries in Computer-Assisted Drug Discovery. *Journal of chemical information and modeling, 59 2*, 644-651 .

[14] Weininger, D. (1988). SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. J. Chem. Inf. Comput. Sci., 28, 31-36.

[15] Simonovsky, M.; Komodakis, N. Graphvae: Towards generation of small graphs using variational autoencoders. In International Conference on Artificial Neural Networks, 2018; Springer: 2018; pp 412-422.

[16] Imrie, F.; Bradley, A. R.; van der Schaar, M.; Deane, C. M., Deep Generative Models for 3D Linker Design.

Journal of Chemical Information and Modeling 2020, 60, 1983-1995.

[17] Gómez-Bombarelli, R., Duvenaud, D.K., Hernández-Lobato, J., Aguilera-Iparraguirre, J., Hirzel, T.D., Adams, R.P., & Aspuru-Guzik, A. (2018). Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules. *ACS Central Science, 4*, 268 - 276.

[18] Simonovsky, M., & Komodakis, N. (2018). GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders. *ICANN*.

[19] Mohammadi S, O'Dowd B, Paulitz-Erdmann C, Goerlitz L. Penalized Variational Autoencoder for Molecular Design. ChemRxiv. Cambridge: Cambridge Open Engage; 2019; This content is a preprint and has not been peer-reviewed.

[20] Flam-Shepherd, D., Wu, T.C., & Aspuru-Guzik, A. (2021). MPGVAE: improved generation of small organic molecules using message passing neural nets. *Machine Learning: Science and Technology*.

[21]Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ...
& Bengio, Y. (2014). Generative adversarial nets. Advances in neural information
processing systems, 27.
[22]Guimaraes, G.L., Sánchez-Lengeling, B., Farias, P.L., & Aspuru-Guzik, A. (2017). Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models. *ArXiv, abs/1705.10843*.

[23]Sánchez-Lengeling, B., Outeiral, C., Guimaraes, G.L., Alán, & Aspuru-Guzik (2017). Optimizing distributions over molecular space . An Objective-Reinforced Generative Adversarial Network for Inverse-design Chemistry ( ORGANIC ).

[24]De Cao, N., & Kipf, T. (2018). MolGAN: An implicit generative model for small molecular graphs. *ArXiv, abs/1805.11973*.

[25]Tsujimoto, Y., Hiwa, S., Nakamura, Y., Oe, Y., & Hiroyasu, T. (2021). L-MolGAN: An improved implicit generative model for large molecular graphs.

[26] Blanchard, A.E., Stanley, C., & Bhowmik, D. (2021). Using GANs with adaptive training data to search for new molecules. *Journal of Cheminformatics, 13*.

[27]Hochreiter S, Schmidhuber J. Long short-term memory. Neu-ral Comput 1997; 9(8): 1735–80.

[28]Cho K, vanMerriënboer B, Gulcehre C, et al. Learning phrase representations using RNN encoder–decoder for statistical machine translation. In: Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing, 2014, 1724–34.Association for Computational Linguistics.

[29]Segler, M.H., Kogej, T., Tyrchan, C., & Waller, M.P. (2018). Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks. *ACS Central Science, 4*, 120 - 131.

[30]Popova, M., Shvets, M., Oliva, J.B., & Isayev, O. (2019). MolecularRNN: Generating realistic molecular graphs with optimized properties. *ArXiv, abs/1905.13372*.

[31]Grisoni, F., Moret, M., Lingwood, R., & Schneider, G. (2020). Bidirectional Molecule Generation with Recurrent Neural Networks. *Journal of chemical information and modeling*.

[32]Madhawa, K., Ishiguro, K., Nakago, K., & Abe, M. (2019). GraphNVP: An Invertible Flow Model for Generating Molecular Graphs. *ArXiv, abs/1905.11600*.

[33]Shi, C., Xu, M., Zhu, Z., Zhang, W., Zhang, M., & Tang, J. (2020). GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation. *ArXiv, abs/2001.09382*.

[34]Zang, C., & Wang, F. (2020). MoFlow: An Invertible Flow Model for Generating Molecular Graphs. *Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining*.

[35] Durk P Kingma and Prafulla Dhariwal. 2018. Glow: Generative flow with in-vertible 1x1 convolutions. In Advances in Neural Information Processing Systems.
10215–10224.

[36]Krenn, M., Hase, F., Nigam, A., Friederich, P., & Aspuru-Guzik, A. (2020). Self-referencing embedded strings (SELFIES): A 100% robust molecular string representation. *Mach. Learn. Sci. Technol., 1*, 45024.

[37] Vaswani, A., Shazeer, N.M., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., & Polosukhin, I. (2017). Attention is All you Need. *ArXiv, abs/1706.03762*.

[38]Radford, A., & Narasimhan, K. (2018). Improving Language Understanding by Generative Pre-Training.



[ChEMBL 24]Gaulton, A., Hersey, A., Nowotka, M., Bento, A.P., Chambers, J., Mendez, D., Mutowo-Meullenet, P., Atkinson, F., Bellis, L.J., Cibrián-Uhalte, E., Davies, M., Dedman, N., Karlsson, A., Magariños, M.P., Overington, J.P., Papadatos, G., Smit, I., & Leach, A.R. (2017). The ChEMBL database in 2017. *Nucleic Acids Research, 45*, D945 - D954.









FCD

[] Preuer, K.; Renz, P.; Unterthiner, T.; Hochreiter, S.; Klambauer,G. Fréchet ChemNet Distance: A Metric for Generative Models for Molecules in Drug Discovery. J. Chem. Inf. Model. 2018, 58, 1736−1741.

KL散度

[]Kullback, S.; Leibler, R. A. On information and sufficiency. Ann.Math. Stat. 1951, 22, 79−86.
$$
D _ { K L } ( P , Q ) = \sum _{ i }P(i)\log\frac { P ( i ) } { Q ( i ) }
$$

$$
S = \frac { 1 } { k } \sum _ { i } ^ { k } e x p ( - D _ { K L , i } )
$$


$$
{ FCD (G ,D) = ||u _{G}-H_{D}||^{ 2 } + T _ { r } (\sum _{G}+\sum_{D}}{ - 2 ( \sum _ { G } \sum _ { D } ) ^ { 1 / 2 } ) }
$$

$$
S = e x p ( - 0.2 F C D )
$$

$$
Q E D = e x p ( \frac { 1 } { n } \sum _ { i = 1 } ^ { n } \ln d _ { i } )
$$

$$
IntDiv_p( G ) = 1 - \sqrt [p] { \frac{1}{|G|^2} \sum _ { m_1,m_2 \in G}T( m_1, m_2 ) ^ { p }} 
$$

[] Benhenda, M. (2017). ChemGAN challenge for drug discovery: can AI reproduce natural chemical diversity? *ArXiv, abs/1708.08227*.



[33]Ma, C., & Zhang, X. (2021). GF-VAE: A Flow-based Variational Autoencoder for Molecule Generation. *Proceedings of the 30th ACM International Conference on Information & Knowledge Management*.



[21]Osakabe, Y., & Asahara, A. (2021). MatVAE: Independently Trained Nested Variational Autoencoder for Generating Chemical Structural Formula. *AAAI Spring Symposium: MLPS*.
$$
U = \{ u _ { 1 } , \cdots , u _ { n } \}
$$

$$
L _ { 1 } (U) = \sum _ { i } \log P ( u _ { i } | u _ { i - k}  , \cdots , u _ { i - 1 } ; \Theta )
$$


$$

$$

$$
\begin{aligned}
&h _ { 0 } = U W _ { e } + W _ { p }\\
&h _ { l } =  transformer\_block( h _ { l - 1 } )\forall_i\in[ 1 , n ]\\
&P ( u ) = softmax( h _ { n } W _ { e } ^ { T } )
\end{aligned}
$$

$$

$$

$$
U = ( u _ { - k } , \cdots , u _ { - 1 } )
$$

$$
P ( y | x ^ { 1 } , \cdots , x ^ { m } ) = softmax( h _ { i } ^ { m } W _ { y } )
$$


$$
L _ { 2 } ( C ) = \sum _ { ( x , y ) } \log P ( y | x ^ { 1 } , \cdots , x ^ { m } )
$$

$$
L _ { 3 } ( C ) = L _ { 2 } ( C ) + \lambda * L _ { 1 } ( C )
$$

$$
( Q , K , V ) = \operatorname { softmax } ( \frac { Q K ^ { T } } { \sqrt { d _ { k } } } ) V 
$$


$$
MultiHead( Q , K , V ) = Concat(head_1,head_2,...,head_h)W^O\tag{2-2}
$$

$$
head_i=Attention(QW_i^{Q},KW_i^{K},VW_i^{V})
$$

$$
W _ { i } ^ { Q } \in \mathbb{R}^{d_{model}×d_k},W _ { i } ^ { K } \in \mathbb{R}^{d_{model}×d_k},W _ { i } ^ { V } \in \mathbb{R}^{d_{model}×d_v},W _ { i } ^ { O } \in \mathbb{R}^{h_{dv}×{d_{model}}}
$$

都是参数矩阵



Greedy Decoding
$$
\hat{y}_{t} = \operatorname { argmax } P ( y _ { t } = w | y _{\lt t} ),w \in V
\tag{6}
$$

$$
\hat y _ { t'}=\underset {y \in \mathcal{Y} } {argmax} P ( y | y _ { 1 } , \cdots , y _ { t '-1 } , \mathbf{c} )
$$

温度采样
$$
P ( x _ { i } | x _ { 1 : i - 1 } ) = \frac {  exp(u_i/ t ) } { \sum _ { j }  exp( u _ { j } / t ) }
$$

$$
\frac { 1 } { L ^ { \alpha } } \log P ( y _ { 1 } \cdots , y _ { L } | c ) = \frac { 1 } { L ^ { \alpha } } \sum _ { t' = 1 } ^ { L } \log P ( y _ { t ^ { \prime } } | y _ { 1 }, \cdots , y _ { t } ^ { \prime } - 1 , c )
$$

Top-k

Angela Fan, Mike Lewis, and Yann Dauphin. 2018. Hi-
erarchical neural story generation. arXiv preprint
arXiv:1805.04833
$$
q(v) = \begin{cases}
p_{\theta}(v|y_{\lt t},C) ,&\text{if v} \in V_k ,\\
b ,&\text{otherwise.}\\
\end{cases}\\
$$

$$
V_k=\underset {v'}  {arg\:topk}\ p_{\theta}( v'| y_{\lt t},\mathbf{c} )
$$

Top-K重采
$$
\hat p _ { i } = \frac { p _ { i } ^ { \prime } } { \sum _ { j = 1 } ^ { |V| } p _ { j } ^ { \prime } }
$$

$$
p _ { i } ^ { \prime } = \operatorname { exp } ( \log ( p _ { i } ) / T ) \cdot \mathbf{1} \{ i \leq K \}
$$

核采样
$$
\sum _ { x \in V ^{(p)} } P ( x | x _ { 1 : i - 1 } ) \geq p
$$

$$
p'=\sum _ { x \in V ^{(p)} } P ( x | x _ { 1 : i - 1 } )
$$

$$
P '( x | x _ { 1 : i - 1 } ) = \begin{cases}
P ( x | x _ { 1 : i - 1 } )/p'  ,&\text{if x} \in V^{(p)},\\
0 ,&\text{otherwise.}\\
\end{cases}\\
$$

```
option = {
  legend: {},
  tooltip: {},
  dataset: {
    dimensions: ['product', 'gua','top_p=0.9', 'top_p=0.95', 'top_k=44,temp=1','top_k=44,temp=0.8'],
    source: [
      { product: 'FCD','gua':1.34,'top_p=0.9': 1.407, 'top_p=0.95': 1.04, 'top_k=44,temp=1': 0.926,'top_k=44,temp=0.8':1.22},
      { product: 'KL Divergence', 'gua':0.974,'top_p=0.9': 0.982, 'top_p=0.95': 0.986, 'top_k=44,temp=1': 0.974,'top_k=44,temp=0.8':0.985},
    
    ]
  },
  xAxis: { type: 'category' },
  yAxis: {},
  // Declare several bar series, each will be mapped
  // to a column of dataset.source by default.
  series: [
    { type: 'bar',
      itemStyle:{
        normal:{
           label:{
             position:'top',
             show:true
             
           }
        }
       
      }
    },
 { type: 'bar',
      itemStyle:{
        normal:{
           label:{
             position:'top',
             show:true
             
           }
        }
       
      }
    },
  { type: 'bar',
      itemStyle:{
        normal:{
           label:{
             position:'top',
             show:true
             
           }
        }
       
      }
    },
  { type: 'bar',
      itemStyle:{
        normal:{
           label:{
             position:'top',
             show:true
             
           }
        }
       
      }
    },
  { type: 'bar',
      itemStyle:{
        normal:{
           label:{
             position:'top',
             show:true
             
           }
        }
       
      }
    },
  ]
};
```

